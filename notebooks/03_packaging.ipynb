{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "disturbed-division",
   "metadata": {},
   "source": [
    "# Packaging Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-pasta",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "- Package the given model using Torch Model Archive\n",
    "- Write a custom handler to support pre processing and post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-honor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "turkish-finland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon\tamazon_trace\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../artifacts/model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "extreme-spirit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\t    setup_config.json\t     tokenizer_config.json\r\n",
      "index_to_name.json  special_tokens_map.json  training_args.bin\r\n",
      "pytorch_model.bin   tokenizer.json\t     vocab.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../artifacts/model/amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sporting-philip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_to_name.json  special_tokens_map.json  traced_model.pt\r\n",
      "model_store\t    tokenizer.json\t     vocab.txt\r\n",
      "setup_config.json   tokenizer_config.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../artifacts/model/amazon_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "outdoor-agenda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: torch-model-archiver [-h] --model-name MODEL_NAME\n",
      "                            [--serialized-file SERIALIZED_FILE]\n",
      "                            [--model-file MODEL_FILE] --handler HANDLER\n",
      "                            [--extra-files EXTRA_FILES]\n",
      "                            [--runtime {python,python2,python3}]\n",
      "                            [--export-path EXPORT_PATH]\n",
      "                            [--archive-format {tgz,no-archive,default}] [-f]\n",
      "                            -v VERSION [-r REQUIREMENTS_FILE]\n",
      "\n",
      "Torch Model Archiver Tool\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --model-name MODEL_NAME\n",
      "                        Exported model name. Exported file will be named as\n",
      "                        model-name.mar and saved in current working directory if no --export-path is\n",
      "                        specified, else it will be saved under the export path\n",
      "  --serialized-file SERIALIZED_FILE\n",
      "                        Path to .pt or .pth file containing state_dict in case of eager mode\n",
      "                        or an executable ScriptModule in case of TorchScript.\n",
      "  --model-file MODEL_FILE\n",
      "                        Path to python file containing model architecture.\n",
      "                        This parameter is mandatory for eager mode models.\n",
      "                        The model architecture file must contain only one\n",
      "                        class definition extended from torch.nn.modules.\n",
      "  --handler HANDLER     TorchServe's default handler name\n",
      "                         or Handler path to handle custom inference logic.\n",
      "  --extra-files EXTRA_FILES\n",
      "                        Comma separated path to extra dependency files.\n",
      "  --runtime {python,python2,python3}\n",
      "                        The runtime specifies which language to run your inference code on.\n",
      "                        The default runtime is \"python\".\n",
      "  --export-path EXPORT_PATH\n",
      "                        Path where the exported .mar file will be saved. This is an optional\n",
      "                        parameter. If --export-path is not specified, the file will be saved in the\n",
      "                        current working directory. \n",
      "  --archive-format {tgz,no-archive,default}\n",
      "                        The format in which the model artifacts are archived.\n",
      "                        \"tgz\": This creates the model-archive in <model-name>.tar.gz format.\n",
      "                        If platform hosting TorchServe requires model-artifacts to be in \".tar.gz\"\n",
      "                        use this option.\n",
      "                        \"no-archive\": This option creates an non-archived version of model artifacts\n",
      "                        at \"export-path/{model-name}\" location. As a result of this choice, \n",
      "                        MANIFEST file will be created at \"export-path/{model-name}\" location\n",
      "                        without archiving these model files\n",
      "                        \"default\": This creates the model-archive in <model-name>.mar format.\n",
      "                        This is the default archiving format. Models archived in this format\n",
      "                        will be readily hostable on native TorchServe.\n",
      "  -f, --force           When the -f or --force flag is specified, an existing .mar file with same\n",
      "                        name as that provided in --model-name in the path specified by --export-path\n",
      "                        will overwritten\n",
      "  -v VERSION, --version VERSION\n",
      "                        Model's version\n",
      "  -r REQUIREMENTS_FILE, --requirements-file REQUIREMENTS_FILE\n",
      "                        Path to a requirements.txt containing model specific python dependency\n",
      "                         packages.\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "torch-model-archiver --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-intelligence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "seasonal-nirvana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch-model-archiver --model-name pt_classifier\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"pt_classifier\"\n",
    "cd .. \n",
    "\n",
    "echo torch-model-archiver --model-name ${MODEL_NAME} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "indoor-burning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_to_name.json  special_tokens_map.json  traced_model.pt\r\n",
      "model_store\t    tokenizer.json\t     vocab.txt\r\n",
      "setup_config.json   tokenizer_config.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../artifacts/model/amazon_trace/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "scenic-catch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_to_name.json  special_tokens_map.json  traced_model.pt\r\n",
      "model_store\t    tokenizer.json\t     vocab.txt\r\n",
      "setup_config.json   tokenizer_config.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../artifacts/model/amazon_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-allocation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "searching-testing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/tutorials/personal/pydata_bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Overwriting artifacts/model/amazon_trace/model_store/pt_classifier.mar ...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd ..\n",
    "pwd\n",
    "\n",
    "ARTIFACT_BASE_DIR=\"artifacts/model/amazon_trace\"\n",
    "\n",
    "MODEL_NAME=\"pt_classifier\"\n",
    "MODEL_VERSION=\"1.0\"\n",
    "MODEL_STORE=\"${ARTIFACT_BASE_DIR}/model_store\"\n",
    "MODEL_SERIALIZED_FILE=\"${ARTIFACT_BASE_DIR}/traced_model.pt\"\n",
    "\n",
    "TOKENIZER_FILES=\"${ARTIFACT_BASE_DIR}/tokenizer_config.json,${ARTIFACT_BASE_DIR}/special_tokens_map.json,${ARTIFACT_BASE_DIR}/vocab.txt,${ARTIFACT_BASE_DIR}/tokenizer.json\"\n",
    "MODEL_EXTRA_FILES=\"${ARTIFACT_BASE_DIR}/index_to_name.json,${ARTIFACT_BASE_DIR}/setup_config.json,${TOKENIZER_FILES}\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mkdir -p $MODEL_STORE\n",
    "\n",
    "torch-model-archiver --model-name ${MODEL_NAME} \\\n",
    "--version ${MODEL_VERSION} \\\n",
    "--serialized-file ${MODEL_SERIALIZED_FILE} \\\n",
    "--export-path ${MODEL_STORE} \\\n",
    "--extra-files ${MODEL_EXTRA_FILES} \\\n",
    "--handler ./serving/handler.py \\\n",
    "--force\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-applicant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-concept",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "intensive-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd .. \n",
    "cp artifacts/model/amazon_trace/model_store/* serving/model_store\n",
    "cp artifacts/model/amazon_trace/setup_config.json serving/model_store/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-hollow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-johnson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "pretty-graphic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchserve --ts-config ./serving/config.properties --start --model-store ./serving/model_store --ncs\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ..\n",
    "echo torchserve --ts-config ./serving/config.properties \\\n",
    "--start --model-store ./serving/model_store --ncs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchserve --stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-currency",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-council",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl \"http://localhost:9081/models\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-wireless",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -X POST http://127.0.0.1:8080/predictions/my_tc -T Seq_classification_artifacts/sample_text_captum_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-disposition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://localhost:9081/models/pt_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -X POST http://localhost:9080/predictions/pt_classifier \\\n",
    "        -H 'Content-Type: application/json' \\\n",
    "        -d '{\"text\":\"herbal tea\",\"request_id\":\"test_id\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-internship",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ..\n",
    "curl -X POST http://localhost:9080/predictions/pt_classifier \\\n",
    "        -H 'Content-Type: application/json' \\\n",
    "        -d @serving/sample_input.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-donna",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -X POST http://localhost:9080/explanations/pt_classifier \\\n",
    "        -H 'Content-Type: application/json' \\\n",
    "        -d '{\"text\":\"herbal tea\",\"request_id\":\"test_id\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-attack",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-geography",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-tennis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-nebraska",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "rapids-gpu.0-18.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/rapids-gpu.0-18:m65"
  },
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

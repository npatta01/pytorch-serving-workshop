{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "parliamentary-metropolitan",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "This is an internal notebok to help create code snippets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-journalist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-attendance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "favorite-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "provincial-electron",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert uses WordPiece Tokenizer\n",
    "# splitting words either into the full forms\n",
    "# (e.g., one word becomes one token) or into word piece\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "homeless-employment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cheap', 'nike', 'men', 'running', 'shoes']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"cheap nike men running shoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "legitimate-employee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['che', '##p', 'nike', 'men', 'shoes', 'run', '##ing', 'under', '100', '$']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chep/runing is mispelled\n",
    "tokenizer.tokenize(\"chep nike men shoes runing under 100$ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mathematical-acceptance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of vocabulary\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-ribbon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "incoming-mentor",
   "metadata": {},
   "source": [
    "# Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hugging face library to load existing/custom datasets\n",
    "import datasets\n",
    "# hugging face library contains tokenizers / models \n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset contains two columns \"text/label\"\n",
    "raw_datasets = datasets.load_from_disk(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use existing distilbert tokenizer\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"distilbert-base-uncased\" )\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# calculate ['input_ids' , 'attention_mask']\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pretrained distilbert model\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\"\n",
    "                                                                        , num_labels=len(labels) ... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = transformers.TrainingArguments(\"trainer\",num_train_epochs=5...)             \n",
    "                                 )\n",
    "trainer = transformers.Trainer(\n",
    "    model=model, \n",
    "    args=training_args, \n",
    "    train_dataset=tokenized_datasets['train'], \n",
    "    eval_dataset=tokenized_datasets['validation'],.... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on datasets/argumets passed to trainer args\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-mother",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "metallic-manor",
   "metadata": {},
   "source": [
    "# Inference Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-mirror",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'comfortable men sandals'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute input id / attention mask\n",
    "tokenized_res = tokenizer.encode_plus(query, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass input to model\n",
    "model_res = model(**tokenized_res)\n",
    "# get softmax of logits\n",
    "logits = model_res.logits\n",
    "softmax_res = torch.softmax(logits, dim=1).toList()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the label and probability sorted\n",
    "predictions = list ( zip (labels , softmax_res ) )\n",
    "predictions = sorted (predictions , key=lambda x:x[1] , reverse =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-marketplace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-mississippi",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-ensemble",
   "metadata": {},
   "source": [
    "# Torch Archiving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name and version of the model\n",
    "MODEL_NAME=\"pt_classifier\"\n",
    "MODEL_VERSION=\"1.0\"\n",
    "\n",
    "# folder where model is saved\n",
    "MODEL_STORE=\"model_store\"\n",
    "# path of saved pytorch models\n",
    "MODEL_SERIALIZED_FILE=\"traced_model.pt\"\n",
    "# path of extra files to include\n",
    "MODEL_EXTRA_FILES=\"index_to_name.json,setup_config.json\"\n",
    "# model code\n",
    "MODEL_CODE=\"handler.py\"\n",
    "\n",
    "\n",
    "torch-model-archiver --model-name ${MODEL_NAME} \\\n",
    "--version ${MODEL_VERSION} \\\n",
    "--serialized-file ${MODEL_SERIALIZED_FILE} \\\n",
    "--export-path ${MODEL_STORE} \\\n",
    "--extra-files ${MODEL_EXTRA_FILES} \\\n",
    "--handler ${MODEL_CODE} \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-crisis",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "rapids-gpu.0-18.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/rapids-gpu.0-18:m65"
  },
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
